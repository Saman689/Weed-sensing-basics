{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook we investigate a designed simple network on PDU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Function, Variable\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "import time as time\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking whether the GPU is active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"/home/saman/Saman/data/PDU_Raw_Data01/Test06_600x30/\")\n",
    "train_path = PATH / 'train' / 'Total'\n",
    "valid_path = PATH / 'valid' / 'Total'\n",
    "test_path = PATH / 'test' / 'Total'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Num_Filter1= 16\n",
    "Num_Filter2= 128\n",
    "Ker_Sz1 = 5\n",
    "Ker_Sz2 = 5\n",
    "\n",
    "learning_rate= 0.0001\n",
    "\n",
    "Dropout= 0.1\n",
    "BchSz= 32\n",
    "EPOCH= 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmenation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode of Augmentation\n",
    "transformation = transforms.Compose([\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0,0,0), (0.5,0.5,0.5)),\n",
    "]) \n",
    "\n",
    "transformation2 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0,0,0), (0.5,0.5,0.5)),    \n",
    "]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading data after augmentation and using batch size to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = torchvision.datasets.ImageFolder(train_path,transform=transformation)\n",
    "train_loader =torch.utils.data.DataLoader(train_data, batch_size=BchSz, shuffle=True,\n",
    "                                          num_workers=8)\n",
    "\n",
    "valid_data = torchvision.datasets.ImageFolder(valid_path,transform=transformation)\n",
    "valid_loader =torch.utils.data.DataLoader(valid_data, batch_size=BchSz, shuffle=True,\n",
    "                                          num_workers=8)\n",
    "\n",
    "test_data = torchvision.datasets.ImageFolder(test_path,transform=transformation2)\n",
    "test_loader =torch.utils.data.DataLoader(test_data, batch_size=BchSz, shuffle=True,\n",
    "                                          num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss calculator\n",
    "criterion = nn.CrossEntropyLoss()   # cross entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a class of our simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet1(nn.Module):\n",
    "    def __init__(self,  Num_Filter1 , Num_Filter2, Ker_Sz1, Ker_Sz2, Dropout, num_classes=2):\n",
    "        super(ConvNet1, self).__init__()\n",
    "        self.layer1 = nn.Sequential(  \n",
    "            nn.Conv2d(              # input shape (3, 30, 600)\n",
    "                in_channels=3,      # input height\n",
    "                out_channels=Num_Filter1,    # n_filters\n",
    "                kernel_size=Ker_Sz1,      # filter size\n",
    "                stride=1,           # filter movement/step\n",
    "                padding=int((Ker_Sz1-1)/2), # if want same width and length of this image after con2d,\n",
    "            ),                      # padding=(kernel_size-1)/2 if stride=1\n",
    "            nn.BatchNorm2d(Num_Filter1),     # Batch Normalization\n",
    "            nn.ReLU(),              # Rectified linear activation\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)) # choose max value in 2x2 area, \n",
    "                                                   # output shape (16, 75, 75)\n",
    "        # Visualizing this in https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(Num_Filter1, Num_Filter2, \n",
    "                      kernel_size=Ker_Sz2, \n",
    "                      stride=1, \n",
    "                      padding=int((Ker_Sz2-1)/2)),\n",
    "            nn.BatchNorm2d(Num_Filter2),                              \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # output shape (64, 38, 38)\n",
    "            nn.Dropout2d(p=Dropout))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(Num_Filter2, 256, \n",
    "                      kernel_size=Ker_Sz2, \n",
    "                      stride=1, \n",
    "                      padding=int((Ker_Sz2-1)/2)),\n",
    "            nn.BatchNorm2d(256),                              \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # output shape (64, 38, 38)\n",
    "            nn.Dropout2d(p=Dropout))\n",
    "        \n",
    "        self.fc = nn.Linear(57600, num_classes) # fully connected layer, output 2 classes\n",
    "        \n",
    "    def forward(self, x):                  # Forwarding the data to classifier \n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1) # flatten the output of conv2 to (batch_size, 64*38*38)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_num_params(model):\n",
    "    TotalParam=0\n",
    "    for param in list(model.parameters()):\n",
    "        print(\"Individual parameters are:\")\n",
    "        nn=1\n",
    "        for size in list(param.size()):\n",
    "            print(size)\n",
    "            nn = nn*size\n",
    "        print(\"Total parameters: {}\" .format(param.numel()))\n",
    "        TotalParam += nn\n",
    "    print('-' * 10)\n",
    "    print(\"Sum of all Parameters is: {}\" .format(TotalParam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_params(model):\n",
    "    TotalParam=0\n",
    "    for param in list(model.parameters()):\n",
    "        nn=1\n",
    "        for size in list(param.size()):\n",
    "            nn = nn*size\n",
    "        TotalParam += nn\n",
    "    return TotalParam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer,  Dropout, learning_rate,  BATCHSIZE, num_epochs):\n",
    "        print(str(datetime.now()).split('.')[0], \"Starting training and validation...\\n\")\n",
    "        print(\"====================Data and Hyperparameter Overview====================\\n\")\n",
    "        print(\"Number of training examples: {} , Number of validation examples: {} \\n\".format(len(train_data), len(valid_data)))\n",
    "              \n",
    "        print(\"Dropout:{:,.2f}, Learning rate: {:,.5f} \" \n",
    "              .format( Dropout, learning_rate ))        \n",
    "        print(\"Batch size: {}, Number of epochs: {} \" \n",
    "              .format(BATCHSIZE, num_epochs)) \n",
    "        \n",
    "        print(\"Number of parameter in the model: {}\". format(get_num_params(model)))\n",
    "              \n",
    "        print(\"================================Results...==============================\\n\")\n",
    "\n",
    "        since = time.time()  #record the beginning time\n",
    "\n",
    "        best_model = model\n",
    "        best_acc = 0.0\n",
    "        acc_vect =[]   \n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for i, (images, labels) in enumerate(train_loader):   \n",
    "                images = Variable(images).cuda()\n",
    "                labels = Variable(labels).cuda()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)            # model output\n",
    "                loss = criterion(outputs, labels)  # cross entropy loss\n",
    "\n",
    "                # Trying binary cross entropy\n",
    "                #loss = criterion(torch.max(outputs.data, 1), labels)\n",
    "                #loss = torch.nn.functional.binary_cross_entropy(outputs, labels)\n",
    "                \n",
    "                \n",
    "\n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()             # clear gradients for this training step\n",
    "                loss.backward()                   # backpropagation, compute gradients\n",
    "                optimizer.step()                  # apply gradients\n",
    "\n",
    "                if (i+1) % 1000 == 0:               # Reporting the loss and progress every 50 step\n",
    "                    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                               .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n",
    "\n",
    "            model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for images, labels in valid_loader:\n",
    "                    images = Variable(images).cuda()\n",
    "                    labels = Variable(labels).cuda()\n",
    "                    \n",
    "                    outputs = model(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss += loss.item()\n",
    "\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "                epoch_loss= loss / total\n",
    "                epoch_acc = 100 * correct / total\n",
    "                acc_vect.append(epoch_acc)\n",
    "\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model = copy.deepcopy(model)\n",
    "\n",
    "                print('Validation accuracy and loss of the model on  {} images: {} %, {:.5f}'\n",
    "                      .format(len(valid_data), 100 * correct / total, loss))\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in train_loader:\n",
    "                images = Variable(images).cuda()\n",
    "                labels = Variable(labels).cuda()\n",
    "                \n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss += loss.item()\n",
    "\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            epoch_loss= loss / total\n",
    "            epoch_acc = 100 * correct / total\n",
    "\n",
    "            print('Train  accuracy and loss of the model on  {} images: {} %, {:.5f}'\n",
    "                  .format(len(train_data), epoch_acc, loss))\n",
    "            print('-' * 10)\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best validation Acc: {:4f}'.format(best_acc)) \n",
    "        \n",
    "        mean_acc = np.mean(acc_vect)\n",
    "        print('Average accuracy on the validation {} images: {}'\n",
    "              .format(len(train_data),mean_acc))\n",
    "        print('-' * 10)\n",
    "        return best_model, mean_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    print(\"Starting testing...\\n\")\n",
    "    model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        test_loss_vect=[]\n",
    "        test_acc_vect=[]\n",
    "        \n",
    "        since = time.time()  #record the beginning time\n",
    "        \n",
    "        for i in range(10):\n",
    "            \n",
    "            Indx = torch.randperm(len(test_data))\n",
    "            Cut=int(len(Indx)/10) # Here 10% showing the proportion of data is chosen for pooling\n",
    "            indices=Indx[:Cut]            \n",
    "            Sampler = Data.SubsetRandomSampler(indices)\n",
    "            pooled_data =  torch.utils.data.DataLoader(test_data , batch_size=BchSz,sampler=Sampler)\n",
    "\n",
    "            for images, labels in pooled_data:\n",
    "                images = Variable(images).cuda()\n",
    "                labels = Variable(labels).cuda()\n",
    "                \n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "            test_loss= loss / total\n",
    "            test_accuracy= 100 * correct / total\n",
    "            \n",
    "            test_loss_vect.append(test_loss)\n",
    "            test_acc_vect.append(test_accuracy)\n",
    "\n",
    "            \n",
    "#             print('Test accuracy and loss for the {}th pool: {:.2f} %, {:.5f}'\n",
    "#                   .format(i+1, test_accuracy, test_loss))\n",
    "            \n",
    "        \n",
    "        mean_test_loss = np.mean(test_loss_vect)\n",
    "        mean_test_acc = np.mean(test_acc_vect)\n",
    "        std_test_acc = np.std(test_acc_vect)\n",
    "        \n",
    "        print('-' * 10)\n",
    "        print('Average of ten test accuracies on test data: {:.2f} %, loss: {:.5f}, Standard deviion of accuracy: {:.4f}'\n",
    "              .format(mean_test_acc, mean_test_loss, std_test_acc))\n",
    "        \n",
    "        print('-' * 10)\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Testing complete in {:.1f}m {:.4f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        \n",
    "        print('-' * 10)\n",
    "        \n",
    "        return mean_test_acc, mean_test_loss, std_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining model with different variables, namely:\n",
    "#### Number of filters in the first and second layer,  Kernel size in the first and second layer , DropOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "988002"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvNet1(Num_Filter1 , Num_Filter2, Ker_Sz1, Ker_Sz2, Dropout, num_classes=2)\n",
    "model = model.cuda()\n",
    "get_num_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet1(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(16, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout2d(p=0.1)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout2d(p=0.1)\n",
      "  )\n",
      "  (fc): Linear(in_features=57600, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet1(Num_Filter1 , Num_Filter2, Ker_Sz1, Ker_Sz2, Dropout, num_classes=2)\n",
    "model = model.cuda()\n",
    "print(model)\n",
    "\n",
    "# Defining optimizer with variable learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer.scheduler=lr_scheduler.ReduceLROnPlateau(optimizer, 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-15 09:28:05 Starting training and validation...\n",
      "\n",
      "====================Data and Hyperparameter Overview====================\n",
      "\n",
      "Number of training examples: 24000 , Number of validation examples: 8000 \n",
      "\n",
      "Dropout:0.10, Learning rate: 0.00010 \n",
      "Batch size: 32, Number of epochs: 5 \n",
      "Number of parameter in the model: 988002\n",
      "================================Results...==============================\n",
      "\n",
      "Validation accuracy and loss of the model on  8000 images: 67.7 %, 1.08737\n",
      "Train  accuracy and loss of the model on  24000 images: 68.0875 %, 0.99648\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 81.275 %, 0.71189\n",
      "Train  accuracy and loss of the model on  24000 images: 83.20833333333333 %, 0.64670\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 77.6125 %, 0.98796\n",
      "Train  accuracy and loss of the model on  24000 images: 88.01666666666667 %, 0.52751\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 83.475 %, 0.72743\n",
      "Train  accuracy and loss of the model on  24000 images: 96.50833333333334 %, 0.37908\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 81.375 %, 1.13656\n",
      "Train  accuracy and loss of the model on  24000 images: 97.4 %, 0.09652\n",
      "----------\n",
      "Training complete in 3m 17s\n",
      "Best validation Acc: 83.475000\n",
      "Average accuracy on the validation 24000 images: 78.2875\n",
      "----------\n",
      "Starting testing...\n",
      "\n",
      "----------\n",
      "Average of ten test accuracies on test data: 77.65 %, loss: 0.00020, Standard deviion of accuracy: 0.4324\n",
      "----------\n",
      "Testing complete in 0.0m 7.0412s\n",
      "----------\n",
      "Seed number:3\n",
      "2019-03-15 09:31:28 Starting training and validation...\n",
      "\n",
      "====================Data and Hyperparameter Overview====================\n",
      "\n",
      "Number of training examples: 24000 , Number of validation examples: 8000 \n",
      "\n",
      "Dropout:0.10, Learning rate: 0.00010 \n",
      "Batch size: 32, Number of epochs: 5 \n",
      "Number of parameter in the model: 988002\n",
      "================================Results...==============================\n",
      "\n",
      "Validation accuracy and loss of the model on  8000 images: 82.95 %, 1.11765\n",
      "Train  accuracy and loss of the model on  24000 images: 96.65 %, 0.34803\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 83.575 %, 0.78111\n",
      "Train  accuracy and loss of the model on  24000 images: 96.60833333333333 %, 0.11373\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 83.7125 %, 0.63668\n",
      "Train  accuracy and loss of the model on  24000 images: 96.5125 %, 0.31050\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 83.075 %, 0.21579\n",
      "Train  accuracy and loss of the model on  24000 images: 96.55833333333334 %, 0.13048\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 83.6 %, 0.91541\n",
      "Train  accuracy and loss of the model on  24000 images: 96.45833333333333 %, 0.22888\n",
      "----------\n",
      "Training complete in 3m 17s\n",
      "Best validation Acc: 83.712500\n",
      "Average accuracy on the validation 24000 images: 83.38250000000001\n",
      "----------\n",
      "Starting testing...\n",
      "\n",
      "----------\n",
      "Average of ten test accuracies on test data: 77.57 %, loss: 0.00020, Standard deviion of accuracy: 0.7583\n",
      "----------\n",
      "Testing complete in 0.0m 7.0438s\n",
      "----------\n",
      "Seed number:11\n",
      "2019-03-15 09:34:52 Starting training and validation...\n",
      "\n",
      "====================Data and Hyperparameter Overview====================\n",
      "\n",
      "Number of training examples: 24000 , Number of validation examples: 8000 \n",
      "\n",
      "Dropout:0.10, Learning rate: 0.00010 \n",
      "Batch size: 32, Number of epochs: 5 \n",
      "Number of parameter in the model: 988002\n",
      "================================Results...==============================\n",
      "\n",
      "Validation accuracy and loss of the model on  8000 images: 83.4875 %, 0.73267\n",
      "Train  accuracy and loss of the model on  24000 images: 96.6 %, 0.21093\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 83.25 %, 0.68342\n",
      "Train  accuracy and loss of the model on  24000 images: 96.6875 %, 0.27755\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 82.8375 %, 0.99323\n",
      "Train  accuracy and loss of the model on  24000 images: 96.59583333333333 %, 0.43208\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 83.125 %, 0.69582\n",
      "Train  accuracy and loss of the model on  24000 images: 96.44583333333334 %, 0.57731\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 83.2625 %, 0.25735\n",
      "Train  accuracy and loss of the model on  24000 images: 96.59166666666667 %, 0.27297\n",
      "----------\n",
      "Training complete in 3m 17s\n",
      "Best validation Acc: 83.487500\n",
      "Average accuracy on the validation 24000 images: 83.19250000000001\n",
      "----------\n",
      "Starting testing...\n",
      "\n",
      "----------\n",
      "Average of ten test accuracies on test data: 77.33 %, loss: 0.00013, Standard deviion of accuracy: 0.2309\n",
      "----------\n",
      "Testing complete in 0.0m 7.0360s\n",
      "----------\n",
      "Seed number:17\n",
      "2019-03-15 09:38:16 Starting training and validation...\n",
      "\n",
      "====================Data and Hyperparameter Overview====================\n",
      "\n",
      "Number of training examples: 24000 , Number of validation examples: 8000 \n",
      "\n",
      "Dropout:0.10, Learning rate: 0.00010 \n",
      "Batch size: 32, Number of epochs: 5 \n",
      "Number of parameter in the model: 988002\n",
      "================================Results...==============================\n",
      "\n",
      "Validation accuracy and loss of the model on  8000 images: 83.125 %, 0.63752\n",
      "Train  accuracy and loss of the model on  24000 images: 96.52916666666667 %, 0.15639\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 83.1 %, 0.91045\n",
      "Train  accuracy and loss of the model on  24000 images: 96.5875 %, 0.13089\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 83.425 %, 0.87466\n",
      "Train  accuracy and loss of the model on  24000 images: 96.4125 %, 0.16312\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 83.2875 %, 0.50529\n",
      "Train  accuracy and loss of the model on  24000 images: 96.425 %, 0.24913\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 83.3875 %, 0.45265\n",
      "Train  accuracy and loss of the model on  24000 images: 96.53333333333333 %, 0.23401\n",
      "----------\n",
      "Training complete in 3m 17s\n",
      "Best validation Acc: 83.425000\n",
      "Average accuracy on the validation 24000 images: 83.265\n",
      "----------\n",
      "Starting testing...\n",
      "\n",
      "----------\n",
      "Average of ten test accuracies on test data: 77.60 %, loss: 0.00020, Standard deviion of accuracy: 0.6186\n",
      "----------\n",
      "Testing complete in 0.0m 6.9963s\n",
      "----------\n",
      "Seed number:19\n",
      "2019-03-15 09:41:41 Starting training and validation...\n",
      "\n",
      "====================Data and Hyperparameter Overview====================\n",
      "\n",
      "Number of training examples: 24000 , Number of validation examples: 8000 \n",
      "\n",
      "Dropout:0.10, Learning rate: 0.00010 \n",
      "Batch size: 32, Number of epochs: 5 \n",
      "Number of parameter in the model: 988002\n",
      "================================Results...==============================\n",
      "\n",
      "Validation accuracy and loss of the model on  8000 images: 83.6375 %, 1.42415\n",
      "Train  accuracy and loss of the model on  24000 images: 96.54583333333333 %, 0.22546\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 83.3125 %, 0.37484\n",
      "Train  accuracy and loss of the model on  24000 images: 96.54166666666667 %, 0.22437\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 83.575 %, 0.76150\n",
      "Train  accuracy and loss of the model on  24000 images: 96.44583333333334 %, 0.25340\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 83.55 %, 0.40096\n",
      "Train  accuracy and loss of the model on  24000 images: 96.46666666666667 %, 0.28261\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 83.0875 %, 0.91152\n",
      "Train  accuracy and loss of the model on  24000 images: 96.49583333333334 %, 0.23269\n",
      "----------\n",
      "Training complete in 3m 18s\n",
      "Best validation Acc: 83.637500\n",
      "Average accuracy on the validation 24000 images: 83.4325\n",
      "----------\n",
      "Starting testing...\n",
      "\n",
      "----------\n",
      "Average of ten test accuracies on test data: 77.66 %, loss: 0.00022, Standard deviion of accuracy: 0.1838\n",
      "----------\n",
      "Testing complete in 0.0m 7.0877s\n",
      "----------\n",
      "Seed number:22\n",
      "----------\n",
      "----------\n",
      "Average of validation accuracies on 5 different random seed: 82.31 %, Average of testing accuracies on 5 different random seed: 77.56 %\n"
     ]
    }
   ],
   "source": [
    "seed= [3, 11, 17, 19, 22]\n",
    "\n",
    "val_acc_vect=[]\n",
    "test_acc_vect=[]\n",
    "\n",
    "\n",
    "for ii in seed: \n",
    "    torch.cuda.manual_seed(ii)\n",
    "    torch.manual_seed(ii)\n",
    "    \n",
    "    model, val_acc= train_model(model, criterion, optimizer,  Dropout, learning_rate,  BchSz, EPOCH)\n",
    "    testing = test_model (model, test_loader)\n",
    "    test_acc= testing[0]\n",
    "    \n",
    "    \n",
    "    val_acc_vect.append( val_acc )\n",
    "    test_acc_vect.append(test_acc)\n",
    "    \n",
    "    mean_val_acc = np.mean(val_acc_vect)\n",
    "    mean_test_acc = np.mean(test_acc_vect)\n",
    "    \n",
    "    print( \"Seed number:{}\" .format(ii))\n",
    "    \n",
    "    \n",
    "print('-' * 10)\n",
    "print('-' * 10)\n",
    "\n",
    "\n",
    "print('Average of validation accuracies on 5 different random seed: {:.2f} %, Average of testing accuracies on 5 different random seed: {:.2f} %'\n",
    "      .format(mean_val_acc, mean_test_acc)) \n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-15 09:45:05 Starting training and validation...\n",
      "\n",
      "====================Data and Hyperparameter Overview====================\n",
      "\n",
      "Number of training examples: 24000 , Number of validation examples: 8000 \n",
      "\n",
      "Dropout:0.10, Learning rate: 0.00010 \n",
      "Batch size: 32, Number of epochs: 5 \n",
      "Number of parameter in the model: 988002\n",
      "================================Results...==============================\n",
      "\n",
      "Validation accuracy and loss of the model on  8000 images: 83.625 %, 0.52612\n",
      "Train  accuracy and loss of the model on  24000 images: 96.5625 %, 0.26136\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 83.35 %, 0.45577\n",
      "Train  accuracy and loss of the model on  24000 images: 96.64166666666667 %, 0.19966\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 83.675 %, 0.73530\n",
      "Train  accuracy and loss of the model on  24000 images: 96.6 %, 0.19548\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 83.475 %, 0.72743\n",
      "Train  accuracy and loss of the model on  24000 images: 96.50833333333334 %, 0.37908\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 83.45 %, 0.80176\n",
      "Train  accuracy and loss of the model on  24000 images: 96.6125 %, 0.17023\n",
      "----------\n",
      "Training complete in 3m 17s\n",
      "Best validation Acc: 83.675000\n",
      "Average accuracy on the validation 24000 images: 83.515\n",
      "----------\n",
      "Starting testing...\n",
      "\n",
      "----------\n",
      "Average of ten test accuracies on test data: 77.65 %, loss: 0.00020, Standard deviion of accuracy: 0.4324\n",
      "----------\n",
      "Testing complete in 0.0m 7.0204s\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "EPOCH= 5\n",
    "\n",
    "seed= 3\n",
    "\n",
    "val_acc_vect=[]\n",
    "test_acc_vect=[]\n",
    "\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "model, val_acc= train_model(model, criterion, optimizer,  Dropout, learning_rate,  BchSz, EPOCH)\n",
    "testing = test_model (model, test_loader)\n",
    "test_acc= testing[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
