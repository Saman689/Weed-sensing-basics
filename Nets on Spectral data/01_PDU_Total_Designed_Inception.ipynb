{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook we investigate a designed simple Inception network on PDU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Function, Variable\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "import time as time\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking whether the GPU is active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"/home/saman/Saman/data/PDU_Raw_Data01/Test06_600x30/\")\n",
    "train_path = PATH / 'train' / 'Total'\n",
    "valid_path = PATH / 'valid' / 'Total'\n",
    "test_path = PATH / 'test' / 'Total'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Num_Filter1= 16\n",
    "Num_Filter2= 64\n",
    "Ker_Sz1 = 5\n",
    "Ker_Sz2 = 5\n",
    "\n",
    "learning_rate= 0.0001\n",
    "\n",
    "Dropout= 0.2\n",
    "BchSz= 32\n",
    "EPOCH= 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode of transformation\n",
    "transformation = transforms.Compose([\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0,0,0), (0.5,0.5,0.5)),\n",
    "]) \n",
    "\n",
    "transformation2 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0,0,0), (0.5,0.5,0.5)),    \n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss calculator\n",
    "criterion = nn.CrossEntropyLoss()   # cross entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a class of our simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,  Num_Filter1 , Num_Filter2, Ker_Sz1, Ker_Sz2,  Dropout, num_classes=2):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(  \n",
    "            nn.Conv2d(              # input shape (3, 30, 600)\n",
    "                in_channels=3,      # input height\n",
    "                out_channels=Num_Filter1,    # n_filters\n",
    "                kernel_size=Ker_Sz1,      # Kernel size\n",
    "                stride=1,           # filter movement/step\n",
    "                padding=int((Ker_Sz1-1)/2), # if want same width and length of this image after con2d,\n",
    "            ),                              # padding=(kernel_size-1)/2 if stride=1\n",
    "            nn.BatchNorm2d(Num_Filter1),     # Batch Normalization\n",
    "            nn.ReLU(),              # Rectified linear activation\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)) # choose max value in 2x2 area, \n",
    "                                                   \n",
    "        # Visualizing this in https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(Num_Filter1, Num_Filter2, \n",
    "                      kernel_size=Ker_Sz2, \n",
    "                      stride=1, \n",
    "                      padding=int((Ker_Sz2-1)/2)),\n",
    "            nn.BatchNorm2d(Num_Filter2),                              \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # output shape (64, 38, 38)\n",
    "            nn.Dropout2d(p=Dropout))\n",
    "        \n",
    "        self.fc = nn.Linear(1050*Num_Filter2, num_classes) # fully connected layer, output 2 classes\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x):                  # Forwarding the data to classifier \n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1) # flatten the output of conv2 to (batch_size, 64*38*38)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining inception classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, out_planes, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_planes, eps=0.001)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        out = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(Inception, self).__init__()\n",
    "        self.branch3x3 = BasicConv2d(in_channels, 384, kernel_size=3, stride=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = BasicConv2d(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = BasicConv2d(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = BasicConv2d(96, 96, kernel_size=3, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch3x3 = self.branch3x3(x)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = self.avgpool(x)\n",
    "\n",
    "        outputs = [branch3x3, branch3x3dbl, branch_pool]\n",
    "        return torch.cat(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_Net(nn.Module):\n",
    "    def __init__(self,  Num_Filter1 , Num_Filter2, Ker_Sz1, Ker_Sz2,  Dropout, num_classes=2):\n",
    "        super(Inception_Net, self).__init__()\n",
    "        self.layer1 = nn.Sequential(  \n",
    "            nn.Conv2d(              # input shape (3, 30, 600)\n",
    "                in_channels=3,      # input height\n",
    "                out_channels=Num_Filter1,    # n_filters\n",
    "                kernel_size=Ker_Sz1,      # Kernel size\n",
    "                stride=1,           # filter movement/step\n",
    "                padding=int((Ker_Sz1-1)/2), # if want same width and length of this image after con2d,\n",
    "            ),                              # padding=(kernel_size-1)/2 if stride=1\n",
    "            nn.BatchNorm2d(Num_Filter1),     # Batch Normalization\n",
    "            nn.ReLU(),              # Rectified linear activation\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)) # choose max value in 2x2 area, \n",
    "                                                   \n",
    "        # Visualizing this in https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(Num_Filter1, Num_Filter2, \n",
    "                      kernel_size=Ker_Sz2, \n",
    "                      stride=1, \n",
    "                      padding=int((Ker_Sz2-1)/2)),\n",
    "            nn.BatchNorm2d(Num_Filter2),                              \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # output shape (64, 38, 38)\n",
    "            nn.Dropout2d(p=Dropout))\n",
    "        \n",
    "        self.Inception = Inception(Num_Filter2)\n",
    "            \n",
    "        self.fc = nn.Linear(120768, num_classes) # fully connected layer, output 2 classes\n",
    "        \n",
    "    def forward(self, x):                  # Forwarding the data to classifier \n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.Inception(out)\n",
    "        out = out.reshape(out.size(0), -1) # flatten the output of conv2 to (batch_size, 64*38*38)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding number of parameter in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_num_params(model):\n",
    "    TotalParam=0\n",
    "    for param in list(model.parameters()):\n",
    "        print(\"Individual parameters are:\")\n",
    "        nn=1\n",
    "        for size in list(param.size()):\n",
    "            print(size)\n",
    "            nn = nn*size\n",
    "        print(\"Total parameters: {}\" .format(param.numel()))\n",
    "        TotalParam += nn\n",
    "    print('-' * 10)\n",
    "    print(\"Sum of all Parameters is: {}\" .format(TotalParam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_params(model):\n",
    "    TotalParam=0\n",
    "    for param in list(model.parameters()):\n",
    "        nn=1\n",
    "        for size in list(param.size()):\n",
    "            nn = nn*size\n",
    "        TotalParam += nn\n",
    "    return TotalParam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer,  Dropout, learning_rate,  BATCHSIZE, num_epochs):\n",
    "        print(str(datetime.now()).split('.')[0], \"Starting training and validation...\\n\")\n",
    "        print(\"====================Data and Hyperparameter Overview====================\\n\")\n",
    "        print(\"Number of training examples: {} , Number of validation examples: {} \\n\".format(len(train_data), len(valid_data)))\n",
    "              \n",
    "        print(\"Dropout:{:,.2f}, Learning rate: {:,.5f} \" \n",
    "              .format( Dropout, learning_rate ))        \n",
    "        print(\"Batch size: {}, Number of epochs: {} \" \n",
    "              .format(BATCHSIZE, num_epochs)) \n",
    "        \n",
    "        print(\"Number of parameter in the model: {}\". format(get_num_params(model)))\n",
    "              \n",
    "        print(\"================================Results...==============================\\n\")\n",
    "\n",
    "        since = time.time()  #record the beginning time\n",
    "\n",
    "        best_model = model\n",
    "        best_acc = 0.0\n",
    "        acc_vect =[]   \n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for i, (images, labels) in enumerate(train_loader):   \n",
    "                images = Variable(images).cuda()\n",
    "                labels = Variable(labels).cuda()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)            # model output\n",
    "                loss = criterion(outputs, labels)  # cross entropy loss\n",
    "\n",
    "                # Trying binary cross entropy\n",
    "                #loss = criterion(torch.max(outputs.data, 1), labels)\n",
    "                #loss = torch.nn.functional.binary_cross_entropy(outputs, labels)\n",
    "                \n",
    "                \n",
    "\n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()             # clear gradients for this training step\n",
    "                loss.backward()                   # backpropagation, compute gradients\n",
    "                optimizer.step()                  # apply gradients\n",
    "\n",
    "                if (i+1) % 1000 == 0:               # Reporting the loss and progress every 50 step\n",
    "                    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                               .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n",
    "\n",
    "            model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for images, labels in valid_loader:\n",
    "                    images = Variable(images).cuda()\n",
    "                    labels = Variable(labels).cuda()\n",
    "                    \n",
    "                    outputs = model(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss += loss.item()\n",
    "\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "                epoch_loss= loss / total\n",
    "                epoch_acc = 100 * correct / total\n",
    "                acc_vect.append(epoch_acc)\n",
    "\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model = copy.deepcopy(model)\n",
    "\n",
    "                print('Validation accuracy and loss of the model on  {} images: {} %, {:.5f}'\n",
    "                      .format(len(valid_data), 100 * correct / total, loss))\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in train_loader:\n",
    "                images = Variable(images).cuda()\n",
    "                labels = Variable(labels).cuda()\n",
    "                \n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss += loss.item()\n",
    "\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            epoch_loss= loss / total\n",
    "            epoch_acc = 100 * correct / total\n",
    "\n",
    "            print('Train  accuracy and loss of the model on  {} images: {} %, {:.5f}'\n",
    "                  .format(len(train_data), epoch_acc, loss))\n",
    "            print('-' * 10)\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best validation Acc: {:4f}'.format(best_acc)) \n",
    "        \n",
    "        mean_acc = np.mean(acc_vect)\n",
    "        print('Average accuracy on the validation {} images: {}'\n",
    "              .format(len(train_data),mean_acc))\n",
    "        print('-' * 10)\n",
    "        return best_model, mean_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    print(\"Starting testing...\\n\")\n",
    "    model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        test_loss_vect=[]\n",
    "        test_acc_vect=[]\n",
    "        \n",
    "        since = time.time()  #record the beginning time\n",
    "        \n",
    "        for i in range(10):\n",
    "            \n",
    "            Indx = torch.randperm(len(test_data))\n",
    "            Cut=int(len(Indx)/10) # Here 10% showing the proportion of data is chosen for pooling\n",
    "            indices=Indx[:Cut]            \n",
    "            Sampler = Data.SubsetRandomSampler(indices)\n",
    "            pooled_data =  torch.utils.data.DataLoader(test_data , batch_size=BchSz,sampler=Sampler)\n",
    "\n",
    "            for images, labels in pooled_data:\n",
    "                images = Variable(images).cuda()\n",
    "                labels = Variable(labels).cuda()\n",
    "                \n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "            test_loss= loss / total\n",
    "            test_accuracy= 100 * correct / total\n",
    "            \n",
    "            test_loss_vect.append(test_loss)\n",
    "            test_acc_vect.append(test_accuracy)\n",
    "\n",
    "            \n",
    "#             print('Test accuracy and loss for the {}th pool: {:.2f} %, {:.5f}'\n",
    "#                   .format(i+1, test_accuracy, test_loss))\n",
    "            \n",
    "        \n",
    "        mean_test_loss = np.mean(test_loss_vect)\n",
    "        mean_test_acc = np.mean(test_acc_vect)\n",
    "        std_test_acc = np.std(test_acc_vect)\n",
    "        \n",
    "        print('-' * 10)\n",
    "        print('Average test accuracy on test data: {:.2f} %, loss: {:.5f}, Standard deviion of accuracy: {:.4f}'\n",
    "              .format(mean_test_acc, mean_test_loss, std_test_acc))\n",
    "        \n",
    "        print('-' * 10)\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Testing complete in {:.1f}m {:.4f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        \n",
    "        print('-' * 10)\n",
    "        \n",
    "        return mean_test_acc, mean_test_loss, std_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying aumentation and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using batch size to load data\n",
    "train_data = torchvision.datasets.ImageFolder(train_path,transform=transformation)\n",
    "train_loader =torch.utils.data.DataLoader(train_data, batch_size=BchSz, shuffle=True,\n",
    "                                          num_workers=8)\n",
    "\n",
    "valid_data = torchvision.datasets.ImageFolder(valid_path,transform=transformation)\n",
    "valid_loader =torch.utils.data.DataLoader(valid_data, batch_size=BchSz, shuffle=True,\n",
    "                                          num_workers=8)\n",
    "\n",
    "test_data = torchvision.datasets.ImageFolder(test_path,transform=transformation2)\n",
    "test_loader =torch.utils.data.DataLoader(test_data, batch_size=BchSz, shuffle=True,\n",
    "                                          num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception_Net(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(16, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout2d(p=0.2)\n",
      "  )\n",
      "  (Inception): Inception(\n",
      "    (branch3x3): BasicConv2d(\n",
      "      (conv): Conv2d(64, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (avgpool): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
      "  )\n",
      "  (fc): Linear(in_features=120768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Inception_Net(Num_Filter1 , Num_Filter2, Ker_Sz1, Ker_Sz2, Dropout, num_classes=2)\n",
    "\n",
    "model = model.cuda()\n",
    "print(model)\n",
    "\n",
    "# Defining optimizer with variable learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer.scheduler=lr_scheduler.ReduceLROnPlateau(optimizer, 'min')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "633378"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-01 15:11:27 Starting training and validation...\n",
      "\n",
      "====================Data and Hyperparameter Overview====================\n",
      "\n",
      "Number of training examples: 24000 , Number of validation examples: 8000 \n",
      "\n",
      "Dropout:0.20, Learning rate: 0.00010 \n",
      "Batch size: 32, Number of epochs: 5 \n",
      "Number of parameter in the model: 633378\n",
      "================================Results...==============================\n",
      "\n",
      "Validation accuracy and loss of the model on  8000 images: 64.9 %, 1.33086\n",
      "Train  accuracy and loss of the model on  24000 images: 62.7375 %, 1.01242\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 75.4 %, 0.76369\n",
      "Train  accuracy and loss of the model on  24000 images: 77.225 %, 1.38264\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 77.35 %, 1.22606\n",
      "Train  accuracy and loss of the model on  24000 images: 87.25833333333334 %, 0.64452\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 72.8875 %, 0.65668\n",
      "Train  accuracy and loss of the model on  24000 images: 88.3125 %, 0.52884\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 79.6875 %, 1.17200\n",
      "Train  accuracy and loss of the model on  24000 images: 95.64583333333333 %, 0.63624\n",
      "----------\n",
      "Training complete in 1m 55s\n",
      "Best validation Acc: 79.687500\n",
      "Average accuracy on the validation 24000 images: 74.045\n",
      "----------\n",
      "Starting testing...\n",
      "\n",
      "----------\n",
      "Average test accuracy on test data: 77.27 %, loss: 0.00026, Standard deviion of accuracy: 0.7046\n",
      "----------\n",
      "Testing complete in 0.0m 5.8832s\n",
      "----------\n",
      "2019-03-01 15:13:28 Starting training and validation...\n",
      "\n",
      "====================Data and Hyperparameter Overview====================\n",
      "\n",
      "Number of training examples: 24000 , Number of validation examples: 8000 \n",
      "\n",
      "Dropout:0.20, Learning rate: 0.00010 \n",
      "Batch size: 32, Number of epochs: 5 \n",
      "Number of parameter in the model: 633378\n",
      "================================Results...==============================\n",
      "\n",
      "Validation accuracy and loss of the model on  8000 images: 80.275 %, 0.75893\n",
      "Train  accuracy and loss of the model on  24000 images: 95.59583333333333 %, 0.11324\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 79.4 %, 1.01741\n",
      "Train  accuracy and loss of the model on  24000 images: 95.62916666666666 %, 0.20947\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 80.3875 %, 0.54221\n",
      "Train  accuracy and loss of the model on  24000 images: 95.6375 %, 0.08113\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 79.375 %, 0.50299\n",
      "Train  accuracy and loss of the model on  24000 images: 95.59583333333333 %, 0.42088\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 80.075 %, 2.54078\n",
      "Train  accuracy and loss of the model on  24000 images: 95.75416666666666 %, 0.24887\n",
      "----------\n",
      "Training complete in 1m 55s\n",
      "Best validation Acc: 80.387500\n",
      "Average accuracy on the validation 24000 images: 79.9025\n",
      "----------\n",
      "Starting testing...\n",
      "\n",
      "----------\n",
      "Average test accuracy on test data: 76.61 %, loss: 0.00041, Standard deviion of accuracy: 0.4764\n",
      "----------\n",
      "Testing complete in 0.0m 5.7241s\n",
      "----------\n",
      "2019-03-01 15:15:28 Starting training and validation...\n",
      "\n",
      "====================Data and Hyperparameter Overview====================\n",
      "\n",
      "Number of training examples: 24000 , Number of validation examples: 8000 \n",
      "\n",
      "Dropout:0.20, Learning rate: 0.00010 \n",
      "Batch size: 32, Number of epochs: 5 \n",
      "Number of parameter in the model: 633378\n",
      "================================Results...==============================\n",
      "\n",
      "Validation accuracy and loss of the model on  8000 images: 80.0625 %, 1.32076\n",
      "Train  accuracy and loss of the model on  24000 images: 95.54166666666667 %, 0.43024\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 79.8875 %, 0.41576\n",
      "Train  accuracy and loss of the model on  24000 images: 95.54166666666667 %, 0.24901\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 79.575 %, 1.62173\n",
      "Train  accuracy and loss of the model on  24000 images: 95.81666666666666 %, 0.24963\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 79.925 %, 2.40927\n",
      "Train  accuracy and loss of the model on  24000 images: 95.60833333333333 %, 0.15915\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 80.1 %, 1.71480\n",
      "Train  accuracy and loss of the model on  24000 images: 95.70416666666667 %, 0.18263\n",
      "----------\n",
      "Training complete in 1m 54s\n",
      "Best validation Acc: 80.100000\n",
      "Average accuracy on the validation 24000 images: 79.91\n",
      "----------\n",
      "Starting testing...\n",
      "\n",
      "----------\n",
      "Average test accuracy on test data: 76.58 %, loss: 0.00036, Standard deviion of accuracy: 0.3228\n",
      "----------\n",
      "Testing complete in 0.0m 5.7930s\n",
      "----------\n",
      "2019-03-01 15:17:29 Starting training and validation...\n",
      "\n",
      "====================Data and Hyperparameter Overview====================\n",
      "\n",
      "Number of training examples: 24000 , Number of validation examples: 8000 \n",
      "\n",
      "Dropout:0.20, Learning rate: 0.00010 \n",
      "Batch size: 32, Number of epochs: 5 \n",
      "Number of parameter in the model: 633378\n",
      "================================Results...==============================\n",
      "\n",
      "Validation accuracy and loss of the model on  8000 images: 79.85 %, 1.32361\n",
      "Train  accuracy and loss of the model on  24000 images: 95.53333333333333 %, 0.22441\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 80.225 %, 1.95208\n",
      "Train  accuracy and loss of the model on  24000 images: 95.63333333333334 %, 0.08277\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 79.425 %, 1.50681\n",
      "Train  accuracy and loss of the model on  24000 images: 95.70416666666667 %, 0.11324\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 80.0625 %, 1.03933\n",
      "Train  accuracy and loss of the model on  24000 images: 95.58333333333333 %, 0.67020\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 79.875 %, 0.84893\n",
      "Train  accuracy and loss of the model on  24000 images: 95.52083333333333 %, 0.12579\n",
      "----------\n",
      "Training complete in 1m 55s\n",
      "Best validation Acc: 80.225000\n",
      "Average accuracy on the validation 24000 images: 79.8875\n",
      "----------\n",
      "Starting testing...\n",
      "\n",
      "----------\n",
      "Average test accuracy on test data: 76.76 %, loss: 0.00031, Standard deviion of accuracy: 0.6555\n",
      "----------\n",
      "Testing complete in 0.0m 5.8354s\n",
      "----------\n",
      "2019-03-01 15:19:29 Starting training and validation...\n",
      "\n",
      "====================Data and Hyperparameter Overview====================\n",
      "\n",
      "Number of training examples: 24000 , Number of validation examples: 8000 \n",
      "\n",
      "Dropout:0.20, Learning rate: 0.00010 \n",
      "Batch size: 32, Number of epochs: 5 \n",
      "Number of parameter in the model: 633378\n",
      "================================Results...==============================\n",
      "\n",
      "Validation accuracy and loss of the model on  8000 images: 79.7625 %, 1.31404\n",
      "Train  accuracy and loss of the model on  24000 images: 95.51666666666667 %, 0.21090\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 79.3125 %, 0.71353\n",
      "Train  accuracy and loss of the model on  24000 images: 95.7 %, 0.29437\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 79.975 %, 0.97653\n",
      "Train  accuracy and loss of the model on  24000 images: 95.67083333333333 %, 0.10430\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 79.4375 %, 1.69258\n",
      "Train  accuracy and loss of the model on  24000 images: 95.55 %, 0.14140\n",
      "----------\n",
      "Validation accuracy and loss of the model on  8000 images: 80.075 %, 1.34002\n",
      "Train  accuracy and loss of the model on  24000 images: 95.53333333333333 %, 0.33516\n",
      "----------\n",
      "Training complete in 1m 57s\n",
      "Best validation Acc: 80.075000\n",
      "Average accuracy on the validation 24000 images: 79.71249999999999\n",
      "----------\n",
      "Starting testing...\n",
      "\n",
      "----------\n",
      "Average test accuracy on test data: 76.57 %, loss: 0.00025, Standard deviion of accuracy: 0.3669\n",
      "----------\n",
      "Testing complete in 0.0m 5.8700s\n",
      "----------\n",
      "----------\n",
      "----------\n",
      "Average of validation accuracies on 5 different random seed: 78.69 %, Average of testing accuracies on 5 different random seed: 76.76 %\n"
     ]
    }
   ],
   "source": [
    "seed= [1, 3, 7, 19, 22]\n",
    "\n",
    "val_acc_vect=[]\n",
    "test_acc_vect=[]\n",
    "\n",
    "\n",
    "for ii in seed: \n",
    "    torch.cuda.manual_seed(ii)\n",
    "    torch.manual_seed(ii)\n",
    "    \n",
    "    model, val_acc= train_model(model, criterion, optimizer,  Dropout, learning_rate,  BchSz, EPOCH)\n",
    "    testing = test_model (model, test_loader)\n",
    "    test_acc= testing[0]\n",
    "    \n",
    "    \n",
    "    val_acc_vect.append( val_acc )\n",
    "    test_acc_vect.append(test_acc)\n",
    "    \n",
    "    mean_val_acc = np.mean(val_acc_vect)\n",
    "    mean_test_acc = np.mean(test_acc_vect)\n",
    "    \n",
    "    \n",
    "print('-' * 10)\n",
    "print('-' * 10)\n",
    "print('Average of validation accuracies on 5 different random seed: {:.2f} %, Average of testing accuracies on 5 different random seed: {:.2f} %'\n",
    "      .format(mean_val_acc, mean_test_acc))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
