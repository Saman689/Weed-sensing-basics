{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt , rcParams, rc\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from scipy.ndimage import imread\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import shutil\n",
    "\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data\n",
    "\n",
    "For plants grown outside the lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mbkg-r1.rawc\u001b[0m*     \u001b[01;32mcan3S1-r1.rawc\u001b[0m*  \u001b[01;32mrad1S1-r1.rawc\u001b[0m*  \u001b[01;32mrad4S1-r1.rawc\u001b[0m*\r\n",
      "\u001b[01;32mcan1S1-r1.rawc\u001b[0m*  \u001b[01;32mcan4S1-r1.rawc\u001b[0m*  \u001b[01;32mrad2S1-r1.rawc\u001b[0m*  \u001b[01;32mrad5S1-r1.rawc\u001b[0m*\r\n",
      "\u001b[01;32mcan2S1-r1.rawc\u001b[0m*  \u001b[01;32mcan5S1-r1.rawc\u001b[0m*  \u001b[01;32mrad3S1-r1.rawc\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "%ls ~/courses/fastai/ESRI/PDU_Raw_Data01/Data-2017-11-06/pdu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/courses/fastai/ESRI/PDU_Raw_Data01/Data-2017-12-04/pdu/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dir= \"/home/ubuntu/courses/fastai/ESRI/PDU_Raw_Data01/\"\n",
    "\n",
    "Stage1= \"Data-2017-11-06/\"\n",
    "Stage2= \"Data-2017-11-13/\"\n",
    "Stage3= \"Data-2017-11-20/\"\n",
    "Stage4= \"Data-2017-11-27/\"\n",
    "Stage5= \"Data-2017-12-04/\"\n",
    "\n",
    "S1Dir=Dir+Stage1+\"pdu/\"\n",
    "S2Dir=Dir+Stage2+\"pdu/\"\n",
    "S3Dir=Dir+Stage3+\"pdu/\"\n",
    "S4Dir=Dir+Stage4+\"pdu/\"\n",
    "S5Dir=Dir+Stage5+\"pdu/\"\n",
    "S5Dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rad5S1-r1.rawc',\n",
       " 'rad3S1-r1.rawc',\n",
       " 'rad1S1-r1.rawc',\n",
       " 'can2S1-r1.rawc',\n",
       " 'rad2S1-r1.rawc',\n",
       " 'can4S1-r1.rawc',\n",
       " 'rad4S1-r1.rawc',\n",
       " 'can5S1-r1.rawc',\n",
       " 'bkg-r1.rawc',\n",
       " 'can1S1-r1.rawc',\n",
       " 'can3S1-r1.rawc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(S1Dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### listing the files in data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(Path, name_prefix='',file_ext='', exclude_ext=' -r1.rawc'):\n",
    "    import os\n",
    "    files = []; # Default return empty list if directory does not exist\n",
    "    \n",
    "    if os.path.isdir(Path):\n",
    "        files = [f for f in os.listdir(Path) if (f.endswith(file_ext) and \\\n",
    "                                                     f.startswith(name_prefix) and \\\n",
    "                                                     (not f.endswith(exclude_ext)) and \\\n",
    "                                                     os.path.isfile(Path+'/'+f) )]\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['can2S3-r1.rawc',\n",
       " 'can3S3-r1.rawc',\n",
       " 'can5S3-r1.rawc',\n",
       " 'can1S3-r1.rawc',\n",
       " 'can4S3-r1.rawc']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1_names= list_files(S3Dir, \"can\")\n",
    "S1_names[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading All files in path of certain day data collection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading files belong to one a certain stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting plants files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['can2S1-r1.rawc', 'can4S1-r1.rawc', 'can5S1-r1.rawc', 'can1S1-r1.rawc', 'can3S1-r1.rawc']\n"
     ]
    }
   ],
   "source": [
    "CanS1_files= list_files(S1Dir, \"can\")\n",
    "CanS2_files= list_files(S2Dir, \"can\")\n",
    "CanS3_files= list_files(S3Dir, \"can\")\n",
    "CanS4_files= list_files(S4Dir, \"can\")\n",
    "CanS5_files= list_files(S5Dir, \"can\")\n",
    "\n",
    "RadS1_files= list_files(S1Dir, \"rad\")\n",
    "RadS2_files= list_files(S2Dir, \"rad\")\n",
    "RadS3_files= list_files(S3Dir, \"rad\")\n",
    "RadS4_files= list_files(S4Dir, \"rad\")\n",
    "RadS5_files= list_files(S5Dir, \"rad\")\n",
    "\n",
    "print CanS1_files[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data path (For only one of the five data collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Up to here\n",
    "\n",
    "Reading file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining reading files function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadingFiles(Path, Files):\n",
    "    %cd {Path}\n",
    "    \n",
    "    Data=[]\n",
    "    for i in range(len(Files)):\n",
    "        Files1= np.loadtxt(Files[i],delimiter=',',dtype=None)\n",
    "        Data.append(Files1)\n",
    "    return Data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/fastai/ESRI/PDU_Raw_Data01/Data-2017-11-06/pdu\n",
      "/home/ubuntu/courses/fastai/ESRI/PDU_Raw_Data01/Data-2017-11-06/pdu\n",
      "/home/ubuntu/courses/fastai/ESRI/PDU_Raw_Data01/Data-2017-11-13/pdu\n",
      "/home/ubuntu/courses/fastai/ESRI/PDU_Raw_Data01/Data-2017-11-13/pdu\n",
      "/home/ubuntu/courses/fastai/ESRI/PDU_Raw_Data01/Data-2017-11-20/pdu\n",
      "/home/ubuntu/courses/fastai/ESRI/PDU_Raw_Data01/Data-2017-11-20/pdu\n",
      "/home/ubuntu/courses/fastai/ESRI/PDU_Raw_Data01/Data-2017-11-27/pdu\n",
      "/home/ubuntu/courses/fastai/ESRI/PDU_Raw_Data01/Data-2017-11-27/pdu\n",
      "/home/ubuntu/courses/fastai/ESRI/PDU_Raw_Data01/Data-2017-12-04/pdu\n",
      "/home/ubuntu/courses/fastai/ESRI/PDU_Raw_Data01/Data-2017-12-04/pdu\n"
     ]
    }
   ],
   "source": [
    "CanS1= ReadingFiles(S1Dir, CanS1_files);\n",
    "RadS1= ReadingFiles(S1Dir, RadS1_files);\n",
    "\n",
    "CanS2= ReadingFiles(S2Dir, CanS2_files);\n",
    "RadS2= ReadingFiles(S2Dir, RadS2_files);\n",
    "\n",
    "CanS3= ReadingFiles(S3Dir, CanS3_files);\n",
    "RadS3= ReadingFiles(S3Dir, RadS3_files);\n",
    "\n",
    "CanS4= ReadingFiles(S4Dir, CanS4_files);\n",
    "RadS4= ReadingFiles(S4Dir, RadS4_files);\n",
    "\n",
    "CanS5= ReadingFiles(S5Dir, CanS5_files);\n",
    "RadS5= ReadingFiles(S5Dir, RadS5_files);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6840, 409), (6837, 409))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CanS3[2].shape, RadS2[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading beam position, lasers reflections and background and stack them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ArrayofLasers(Array): \n",
    "    beam_position=Array[:,0]\n",
    "    L635 = Array[:,1::4]\n",
    "    L685 = Array[:, 2::4]\n",
    "    L785 = Array[:, 3::4]\n",
    "    BKG = Array[:, 4::4]\n",
    "    \n",
    "    # Making beam positions equal to Laser size to stack    \n",
    "    beam_position_matrix = np.empty((L635.shape[0],L635.shape[1]))\n",
    "    for i in range(L635.shape[1]):\n",
    "        beam_position_matrix[:,i] = beam_position\n",
    "        \n",
    "    TotArr = np.stack([beam_position_matrix, L635, L685, L785, BKG])\n",
    "    return TotArr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing ArrayofLasers function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 6951, 102), (5, 6954, 102), 15.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Can1S1= ArrayofLasers(CanS1[0]);\n",
    "Can2S1= ArrayofLasers(CanS1[1]);\n",
    "#..\n",
    "Can1S1.shape, Can2S1.shape, Can1S1[4][5000][80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just testing: Writting preliminary code fro testing, before writting the AllFiveFiles function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking the mininimum scan lines finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making an array of all 5 files in each stage\n",
    "\n",
    "The first argument shows file number, (not yet)\n",
    "\n",
    "The second one is 0=beam_position_matrix, 1=L635, 2=L685, 3=L785, 4=BKG\n",
    "\n",
    "The third one is number of lines in scans\n",
    "\n",
    "The last one is beam reflection number=102\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AllFiveFiles(TotArr):\n",
    "    A=[]\n",
    "\n",
    "    for i in range(len(TotArr)):\n",
    "        B=TotArr[i].shape[0]\n",
    "        A.append(B)\n",
    "    Line_min=np.min(A)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Bigarray = np.empty((len(TotArr),5,Line_min,102))\n",
    "    for i in range(5):\n",
    "        Bigarray[i,...] = ArrayofLasers(TotArr[i])[:,:Line_min,:]\n",
    "    return Bigarray    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing all files function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AllFiveFiles(CanS1)[1][3][5000:5050][19:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CanS1Data=AllFiveFiles(CanS1)\n",
    "RadS1Data=AllFiveFiles(RadS1)\n",
    "\n",
    "CanS2Data=AllFiveFiles(CanS2)\n",
    "RadS2Data=AllFiveFiles(RadS2)\n",
    "\n",
    "CanS3Data=AllFiveFiles(CanS3)\n",
    "RadS3Data=AllFiveFiles(RadS3)\n",
    "\n",
    "CanS4Data=AllFiveFiles(CanS4)\n",
    "RadS4Data=AllFiveFiles(RadS4)\n",
    "\n",
    "CanS5Data=AllFiveFiles(CanS5)\n",
    "RadS5Data=AllFiveFiles(RadS5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([109.,  11.,  79.,  12.,  63.,  15.,  48.,  32.,   7.,  18.,   5.,\n",
       "         12.,   0.,  21.,   0.,  23.,   1.,  68.,   3.,  70.,   2.,  93.,\n",
       "          3.,  50.,   2., 100.,   2.,  67.,   1.,  49.]), (5, 5, 6951, 102))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CanS1Data[0, 1, 200, 57:87], CanS1Data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making NN Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Dir+ 'Test08_reshape750x750/'\n",
    "if not os.path.exists(path): os.mkdir(path) \n",
    "os.chdir(path)\n",
    "#path\n",
    "\n",
    "train_path= path + 'train/'\n",
    "if not os.path.exists(train_path): os.mkdir(train_path) \n",
    "#train_path\n",
    "\n",
    "valid_path= path + 'valid/'\n",
    "if not os.path.exists(valid_path): os.mkdir(valid_path) \n",
    "#valid_path\n",
    "\n",
    "test_path= path + 'test/'\n",
    "if not os.path.exists(test_path): os.mkdir(test_path) \n",
    "#test_path\n",
    "\n",
    "sample_path= path + 'sample/'\n",
    "if not os.path.exists(sample_path): os.mkdir(sample_path) \n",
    "#sample_path\n",
    "\n",
    "model_path= path + 'models/'\n",
    "if not os.path.exists(model_path): os.mkdir(model_path) \n",
    "#model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see all the array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a function to get window sizes and give data matrixes (frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left lasers =18:48  Right lasers=57:87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to write some part to clean all the folders \n",
    "\n",
    "def GettingFiles(Dataset,  Stage, Type, num_of_wins=200,  Skip=1, num_lines=750):\n",
    "    '''Dataset: Variables Dataset \n",
    "    Stage= Enter your Stage as an string Ex: Stage1\n",
    "    Type= Enter your Type of your plant Ex: Canola\n",
    "    num_of_wins=Number of windows we wish to have\n",
    "    If we want to skip a line: Skip\n",
    "    Number of scans: Num_lines default=750\n",
    "    '''\n",
    "    targ=750\n",
    "    Num_of_wins=num_of_wins  # Number of windows we want in each side\n",
    "    Num_lines=num_lines\n",
    "    skip=Skip    \n",
    "\n",
    "    Left_side_Width= range(18,48)\n",
    "    Right_side_Width= range(57,87)\n",
    "    Side= [Left_side_Width, Right_side_Width] # 0=Left  1=Right\n",
    "\n",
    "    DataFrame_L635=[]\n",
    "    DataFrame_L685=[]\n",
    "    DataFrame_L785=[]\n",
    "    DataFrame_BKG=[]\n",
    "\n",
    "    # Selecting randomly the window frames among all the line scans \n",
    "    np.random.seed(1000)\n",
    "    Total_length_Size= Dataset.shape[2]\n",
    "    End=Total_length_Size-Num_lines-200  # 200 is reduced from end due to soil area\n",
    "    Start=sorted(np.random.randint(100, End, Num_of_wins)) # Start at 100 line due to the soil\n",
    " \n",
    "    Im3D= np.zeros((len(Left_side_Width),Num_lines/skip,3), 'uint8')\n",
    "    Im4D= np.zeros((len(Left_side_Width),Num_lines/skip,4), 'uint8')\n",
    "\n",
    "    # The three first dataset is devoted to the training and the forth for \n",
    "    # the validation and the last set as the testing \n",
    "    i=0 \n",
    "    for ii in range(5):\n",
    "        if ii==4:\n",
    "            os.chdir(test_path)\n",
    "            i=0\n",
    "        elif ii==3:\n",
    "            os.chdir(valid_path)\n",
    "            i=0\n",
    "        else:\n",
    "            os.chdir(train_path)\n",
    "        # We need to give to the function the Stage ex: Stage=\"Stage1\"\n",
    "        S='/'+Stage+'/'\n",
    "        stage_path= os.getcwd() + S\n",
    "        if not os.path.exists(stage_path): os.mkdir(stage_path) \n",
    "        os.chdir(stage_path)\n",
    "\n",
    "        PlantType_Path= stage_path+Type\n",
    "        if not os.path.exists(PlantType_Path): os.mkdir(PlantType_Path)\n",
    "        os.chdir(PlantType_Path)\n",
    "\n",
    "\n",
    "        for side in Side:\n",
    "            for start in Start:\n",
    "                WinL635= Dataset[ii,1,start:start+Num_lines:skip, side]\n",
    "                WinL685= Dataset[ii,2,start:start+Num_lines:skip, side]\n",
    "                WinL785= Dataset[ii,3,start:start+Num_lines:skip, side]\n",
    "                WinBKG= Dataset[ii,4,start:start+Num_lines:skip, side]\n",
    "\n",
    "                DataFrame_L635.append(WinL635)\n",
    "                DataFrame_L685.append(WinL685)\n",
    "                DataFrame_L785.append(WinL785)\n",
    "                DataFrame_BKG.append(WinBKG)\n",
    "\n",
    "                Im3D[..., 0]= WinL635\n",
    "                Im4D[..., 0]= WinL635\n",
    "\n",
    "                Im3D[..., 1]= WinL685\n",
    "                Im4D[..., 1]= WinL685\n",
    "\n",
    "                Im3D[..., 2]= WinL785\n",
    "                Im4D[..., 2]= WinL785\n",
    "\n",
    "                Im4D[..., 3]= WinBKG\n",
    "\n",
    "                img3d = Image.fromarray(Im3D)\n",
    "                # Resizing the images\n",
    "                img3d = img3d.resize((targ,targ), Image.BICUBIC)\n",
    "                \n",
    "                img4d = Image.fromarray(Im4D)\n",
    "\n",
    "                i=i+1\n",
    "                img3d.save(Stage+\"_\"+str(i)+\".jpeg\")\n",
    "\n",
    "    #for StrWidth in Right_side_Win:\n",
    "    #DataFrame_L635   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting files and saving them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GettingFiles(CanS1Data, Stage=\"Stage1\", Type= \"Canola\")\n",
    "GettingFiles(CanS2Data, Stage=\"Stage2\", Type= \"Canola\")\n",
    "GettingFiles(CanS3Data, Stage=\"Stage3\", Type= \"Canola\")\n",
    "GettingFiles(CanS4Data, Stage=\"Stage4\", Type= \"Canola\")\n",
    "GettingFiles(CanS5Data, Stage=\"Stage5\", Type= \"Canola\")\n",
    "\n",
    "GettingFiles(RadS1Data, Stage=\"Stage1\", Type= \"Radish\")\n",
    "GettingFiles(RadS2Data, Stage=\"Stage2\", Type= \"Radish\")\n",
    "GettingFiles(RadS3Data, Stage=\"Stage3\", Type= \"Radish\")\n",
    "GettingFiles(RadS4Data, Stage=\"Stage4\", Type= \"Radish\")\n",
    "GettingFiles(RadS5Data, Stage=\"Stage5\", Type= \"Radish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making total folder for each dataset and copy the stages in to the total folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= [train_path, test_path, valid_path]\n",
    "St= [\"Stage1\",\"Stage2\",\"Stage3\",\"Stage4\",\"Stage5\"]\n",
    "\n",
    "for Path in path:\n",
    "    os.chdir(Path)\n",
    "    Tot_Path= Path+\"/Total\"\n",
    "    if not os.path.exists(Tot_Path): os.mkdir(Tot_Path)        \n",
    "    \n",
    "    \n",
    "    Can_DIR= Tot_Path+\"/Canola\"\n",
    "    if not os.path.exists(Can_DIR): os.mkdir(Can_DIR)\n",
    "        \n",
    "    Rad_DIR= Tot_Path+\"/Radish\"\n",
    "    if not os.path.exists(Rad_DIR): os.mkdir(Rad_DIR) \n",
    "        \n",
    "    for Stage in St: \n",
    "        SrcC= Path+Stage+\"/Canola\"\n",
    "        SrcR= Path+Stage+\"/Radish\"\n",
    "\n",
    "        SrcC_files = os.listdir(SrcC)                \n",
    "        for file_name in SrcC_files:\n",
    "            full_file_name = os.path.join(SrcC, file_name)\n",
    "            if (os.path.isfile(full_file_name)):\n",
    "                shutil.copy(full_file_name, Can_DIR)\n",
    "\n",
    "        SrcR_files = os.listdir(SrcR)                \n",
    "        for file_name in SrcR_files:\n",
    "            full_file_name = os.path.join(SrcR, file_name)\n",
    "            if (os.path.isfile(full_file_name)):\n",
    "                shutil.copy(full_file_name, Rad_DIR)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting one of the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Defining the plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(Rad_DIR)\n",
    "Rad_images= os.listdir(Rad_DIR)\n",
    "Rad_images[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "display(Image(Rad_images[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10), frameon=False)\n",
    "plt.imshow(mpimg.imread(Rad_images[3]), aspect='auto', cmap='viridis')\n",
    "mpimg.imread(Rad_images[3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10), frameon=False)\n",
    "\n",
    "plt.imshow(mpimg.imread(Rad_images[3])[0:80,:], aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
